[Main]

# The host of the Datadog intake server to send agent data to
dd_url: https://app.datadoghq.com

# The Datadog api key to associate your agent's data with your organization.
# Can be found here:
# https://app.datadoghq.com/account/settings
api_key: APIKEYHERE

# If you need a proxy to connect to the Internet, provide the settings here
# proxy_host: my-proxy.com
# proxy_port: 3128
# proxy_user: user
# proxy_password: password

# Boolean to enable debug_mode, which outputs massive amounts of log messages
# to the /tmp/ directory.
debug_mode: no

# Force the hostname to whatever you want.
#hostname: mymachine.mydomain

# Set the host's tags
#tags: mytag0, mytag1

# Use mount points instead of volumes to track disk and fs metrics
use_mount: no

# Change port the agent is listening to
# listen_port: 17123

# Start a graphite listener on this port
# graphite_listen_port: 17124

# Certificate file.
# ca_certs = datadog-cert.pem

# ========================================================================== #
# Pup configuration
# ========================================================================== #

# Pup is a small server that displays metric data collected by the agent.
# Think of it as a fancy status page or a toe dip into the world of
# datadog. It can be connected to on the port below.

# use_pup: yes
# pup_port: 17125
# pup_url: http://localhost:17125

# ========================================================================== #
# DogStatsd configuration                                                    #
# ========================================================================== #

# DogStatsd is a small server that aggregates your custom app metrics. For
# usage information, check out http://api.datadoghq.com

#  Make sure your client is sending to the same port.
# dogstatsd_port : 8125

# By default dogstatsd will post aggregate metrics to the agent (which handles
# errors/timeouts/retries/etc). To send directly to the datadog api, set this
# to https://app.datadoghq.com.
# dogstatsd_target : http://localhost:17123

## The dogstatsd flush period.
# dogstatsd_interval : 10


# ========================================================================== #
# Service-specific configuration                                             #
# ========================================================================== #

# -------------------------------------------------------------------------- #
#   Ganglia                                                                  #
# -------------------------------------------------------------------------- #

# Ganglia host where gmetad is running
#ganglia_host: localhost

# Ganglia port where gmetad is running
#ganglia_port: 8651

# -------------------------------------------------------------------------- #
#   Cassandra                                                                #
# -------------------------------------------------------------------------- #
#cassandra_host: localhost
#cassandra_port: 8080
#cassandra_nodetool: /usr/bin/nodetool

# -------------------------------------------------------------------------- #
#   Nagios                                                                   #
# -------------------------------------------------------------------------- #

# dd-agent imports alerts and perfdata from nagios.

# Path to Nagios' event log file
# Make sure the dd-agent user can read this file
#nagios_log: /var/log/nagios3/nagios.log

# If you use perfdata, dd-agent can import automatically and in real-time
# performance data collected by nagios.
# For more information on perfdata configuration, please refer to
# http://nagios.sourceforge.net/docs/3_0/perfdata.html
#
# Path to Nagios' ***configuration*** file where the properties
# host|service_perfdata_file and host|service_perfdata_file_template
# are defined.
# (ubuntu 10.04)
#nagios_perf_cfg: /etc/nagios3/nagios.cfg
# (centos 5)
#nagios_perf_cfg: /etc/nagios/nagios.cfg




# -------------------------------------------------------------------------- #
#  Memcache
# -------------------------------------------------------------------------- #

#memcache_server: localhost
#memcache_port: 11211

# -------------------------------------------------------------------------- #
#  Dogstream (log file parser)
# -------------------------------------------------------------------------- #

# Comma-separated list of logs to parse and optionally custom parsers to use.
# The form should look like this:
#
#   dogstreams: /path/to/log1:parsers_module:custom_parser, /path/to/log2, /path/to/log3, ...
#
# Or this:
#
#   dogstreams: /path/to/log1:/path/to/my/parsers_module.py:custom_parser, /path/to/log2, /path/to/log3, ...
#
# Each entry is a path to a log file and optionally a Python module/function pair
# separated by colons.
#
# Custom parsers should take a 2 parameters, a logger object and
# a string parameter of the current line to parse. It should return a tuple of
# the form:
#   (metric (str), timestamp (unix timestamp), value (float), attributes (dict))
# where attributes should at least contain the key 'metric_type', specifying
# whether the given metric is a 'counter' or 'gauge'.
#
# Unless parsers are specified with an absolute path, the modules must exist in
# the agent's PYTHONPATH. You can set this as an environment variable when
# starting the agent. If the name of the custom parser function is not passed,
# 'parser' is assumed.
#
# If this value isn't specified, the default parser assumes this log format:
#     metric timestamp value key0=val0 key1=val1 ...
#

# ========================================================================== #
# Custom Emitters                                                            #
# ========================================================================== #

# Comma-separated list of emitters to be used in addition to the standard one
#
# Expected to be passed as a comma-separated list of colon-delimited
# name/object pairs.
#
# custom_emitters: /usr/local/my-code/emitters/rabbitmq.py:RabbitMQEmitter
#
# If the name of the emitter function is not specified, 'emitter' is assumed.


# ========================================================================== #
# Custom Checks
# ========================================================================== #

# Comma-separated list of additional metric checks
#
# Expected to be passed as a comma-separated list of colon-delimited
# name/object pairs.
#
# custom_checks: /usr/local/my-code/checks/foo.py:FooCheck
#
# If the name of the check is not specified, 'Check' is assumed.

##############################################################################
#################### NOTHING TO MODIFY AFTER THIS LINE #######################
##############################################################################

# -------------------------------------------------------------------------- #
#  Logging Configuration
#
#  PLEASE READ ME!
#
#  DO NOT PUT ANY INTEGRATION CONFIGURATION AFTER THIS SECTION
#  IT WILL BE IGNORED.
#  I REPEAT, IT WILL BE IGNORED.
#
# -------------------------------------------------------------------------- #

[loggers]
keys:root,dogstatsd,checks,config

[handlers]
keys:dogstatsd,ddagent

[formatters]
keys:ddagent

# DogStatsd logging

[logger_root]
level:ERROR
handlers:ddagent
propagate:0
qualname:root

[logger_dogstatsd]
level:ERROR
handlers:dogstatsd
propagate:0
qualname:dogstatsd

[logger_checks]
level:ERROR
handlers:ddagent
propogate:0
qualname:checks

[logger_config]
level:ERROR
handlers:ddagent
propogate:0
qualname:config

[handler_dogstatsd]
class:handlers.NTEventLogHandler
formatter:ddagent
args=('DogstatsD', '', 'Application')

[handler_ddagent]
class:handlers.NTEventLogHandler
formatter:ddagent
args=('Datadog Agent', '', 'Application')

[handler_ddforwarder]
class:handlers.NTEventLogHandler
formatter:ddagent
args=('Datadog Forwarder', '', 'Application')

[formatter_ddagent]
format: %(asctime)s | %(name)s | %(levelname)s | %(message)s
class:logging.Formatter

# IF YOU ADD ANYTHING HERE, IT WILL BE IGNORED
# SO IF YOU WANT TO CONFIGURE AN INTEGRATION,
# DO IT IN THE SECTION ABOVE

